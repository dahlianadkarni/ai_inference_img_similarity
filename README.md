# Photo Near-Duplicate Detection (macOS Photos)

Finds groups of near-duplicate photos using OpenCLIP embeddings, then lets you review them in a local web UI and optionally delete selected photos from Apple Photos.

**ğŸ“š Documentation:**
- **[PLAN.md](PLAN.md)** â€” 5-step infrastructure learning plan (Step 1, 2 & 3 complete âœ…)
- **[DOCKER_README.md](DOCKER_README.md)** â€” Docker containerization guide with security best practices
- **[GPU_DEPLOYMENT.md](GPU_DEPLOYMENT.md)** â€” Cloud GPU deployment guide (Vast.ai, RunPod, Lambda Labs)
- **[DEMO_SETUP_CLEAN.md](DEMO_SETUP_CLEAN.md)** â€” Demo mode setup (separate server on port 8001)
- **[docs/IMPLEMENTATION_NOTES.md](docs/IMPLEMENTATION_NOTES.md)** â€” Project history and implementation notes

## What It Does

- **Scans photos** from Apple Photos (via AppleScript) or any directory
- **Detects duplicates** at three levels:
  - Exact duplicates (MD5 hash matching)
  - Perceptual duplicates (dHash - finds resized/edited versions)
  - AI similar groups (OpenCLIP embeddings - finds semantically similar photos)
- **Review UI** with separate workflows:
  - **Exact Duplicates**: Auto-selected by default, batch delete with one click
  - **Perceptual Duplicates**: Manual review, check groups to activate
  - **AI Groups**: Fine-grained selection, teach the AI with feedback
- **Smart features**:
  - Keeps oldest photo by default (based on EXIF date)
  - Shows disk savings in real-time
  - Full-screen modal with keyboard navigation
  - Individual image toggle within groups

## Quickstart

See DEMO_SETUP.md and DEMO_SOLUTION.md for demo

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Start UI only (port 8000)
python -m src.ui.main

# Or start both inference + UI
python start_services.py

# Or use demo dataset (UI on port 8001; inference runs on port 8002)
python start_services.py --ui-demo
```

Open http://127.0.0.1:8000 (or the demo UI at http://127.0.0.1:8001). The inference service runs on http://127.0.0.1:8002.

## End-to-End Workflow (How the Pieces Fit)

### Step 1 â€” Scan

Produces a JSON list of images to analyze.

- Output: scan_for_embeddings.json
- UI: Use the â€œControl Panel â†’ Start Scanâ€ button
- CLI (optional):

```bash
source venv/bin/activate
python -m src.scanner.main --photos-library --use-applescript --keep-export --limit 200
```

Tip: With `--keep-export`, AppleScript exports into `.cache/photos_export` by default and subsequent scans can be incremental (it skips re-exporting files that are already present).

macOS will prompt â€œTerminal wants to control Photosâ€ on first run. Allow it.

If you want estimates before running a full scan of your Photos â€œoriginalsâ€ (Full Disk Access required), run:

```bash
source venv/bin/activate
python -m src.scanner.main --photos-library --estimate --estimate-sample 200
```

### Step 2 â€” Generate Embeddings + Similarity Groups

Computes embeddings and writes similarity groups to disk.

- Output directory: embeddings/
- Group output: embeddings/similar_groups.json
- UI: Use â€œControl Panel â†’ Generate Embeddingsâ€ and set your threshold
- CLI (optional):

```bash
source venv/bin/activate
python -m src.embedding.main scan_for_embeddings.json --output embeddings --similarity-threshold 0.85
```

Notes:
- Higher thresholds (e.g., 0.95â€“0.99) are stricter.
- Embeddings are cleared before regenerating so old data doesnâ€™t accumulate.

### Step 3 â€” Review Groups (Delete / Keep / Feedback)

The UI has three tabs:

**Scanner Results Tab:**
- **Exact Duplicates** (green theme): All groups checked by default, oldest photo kept
  - Uncheck groups to exclude from batch delete
  - Click thumbnails to toggle individual images (KEEP â˜… / DEL âœ—)
  - Click Delete Selected to remove marked photos
- **Perceptual Duplicates** (orange theme): Manual review workflow
  - Check groups to activate them
  - Same toggle functionality as exact duplicates
  - Review and delete in batches

**AI Results Tab:**
- Side-by-side comparison of similar groups
- Delete Selected: deletes chosen photos from Apple Photos
- Keep All: marks the group reviewed
- Not Similar (Teach AI): stores "negative examples" in embeddings/feedback.pkl

**Universal Features:**
- ğŸ” Click to open full-screen modal with prev/next navigation
- Real-time disk savings calculation
- Keyboard shortcuts in modal (â† â†’ arrows, ESC to close)

### Step 4 â€” Re-analyze With Feedback

After giving feedback, click â€œRe-analyze with Feedbackâ€ (or regenerate embeddings) to apply the learned penalties/boosts during grouping.

## Outputs

- scan_for_embeddings.json â€” scan results used for embedding generation
- embeddings/embeddings.npy + embeddings/metadata.json â€” stored embeddings
- embeddings/similar_groups.json â€” groups to review
- embeddings/feedback.pkl â€” persisted feedback examples

## Architecture

The app uses a **client-service architecture** â€” the same pattern used by production inference systems like Triton, TorchServe, and vLLM.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client/UI          â”‚         â”‚ Inference Service    â”‚
â”‚  (Port 8000)         â”‚â”€HTTPâ”€â”€â†’ â”‚  (Port 8002)         â”‚
â”‚                      â”‚         â”‚                      â”‚
â”‚ â€¢ Scan photos       â”‚         â”‚ â€¢ Load model         â”‚
â”‚ â€¢ Call service      â”‚         â”‚ â€¢ Generate embeddingsâ”‚
â”‚ â€¢ Store embeddings  â”‚         â”‚ â€¢ Return JSON        â”‚
â”‚ â€¢ Group results     â”‚         â”‚ â€¢ Stateless API      â”‚
â”‚ â€¢ Display UI        â”‚         â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Principles:**
- **Separation of Concerns**: Client handles photos/metadata, service handles ML inference
- **Stateless Service**: Each request is independent, enabling horizontal scaling
- **Clean HTTP Boundary**: Services communicate via JSON/REST APIs
- **Independent Deployment**: Can run on same machine or separate GPU server

**Three Embedding Modes:**
```bash
# Local mode (original behavior - model loads inline)
python -m src.embedding.main_v2 scan_for_embeddings.json --mode local

# Remote mode (calls inference service)
python -m src.embedding.main_v2 scan_for_embeddings.json --mode remote

# Auto mode (tries remote, falls back to local)
python -m src.embedding.main_v2 scan_for_embeddings.json
```

See [DOCKER_README.md](DOCKER_README.md) for containerization details.

## Repo Map

- src/scanner/ â€” scanning + AppleScript Photos export
- src/embedding/ â€” OpenCLIP embedding generation + storage
- src/inference_service/ â€” stateless FastAPI inference server
- src/grouping/ â€” clustering + feedback learner
- src/ui/ â€” FastAPI UI server

## Safety Notes

- Everything runs locally by default.
- Deletion uses AppleScript to delete photos from the Photos library; start by testing on a small limit.



Step	Time	Resource	Bottleneck
1. Scanner	1-5 min	I/O + CPU	File reading, hash computation
2. Embedding	10-30 sec	GPU/MPS	Neural network (MAIN BOTTLENECK)
3. Grouping	<1 sec	CPU	Just math on vectors
4. UI	Instant	Memory	Display